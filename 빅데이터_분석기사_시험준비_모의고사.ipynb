{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgs2285/BigData_Analysis_License/blob/master/%E1%84%87%E1%85%B5%E1%86%A8%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5_%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%E1%84%80%E1%85%B5%E1%84%89%E1%85%A1_%E1%84%89%E1%85%B5%E1%84%92%E1%85%A5%E1%86%B7%E1%84%8C%E1%85%AE%E1%86%AB%E1%84%87%E1%85%B5_%E1%84%86%E1%85%A9%E1%84%8B%E1%85%B4%E1%84%80%E1%85%A9%E1%84%89%E1%85%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1회차\n",
        "\n",
        "## 1 유형\n",
        "\n",
        "주어지는 데이터는 153일 동안 공기의 질을 측정한 데이터셋이다.\n",
        "* Ozone : 오존농도\n",
        "* Solar.R : 태양 복사 강도\n",
        "* Wind : 평균 풍속\n",
        "* Temp : 최대 온도\n",
        "* Month : 월\n",
        "* Day : 일\n",
        "\n",
        "1. airquality 데이터에 대해서 결측치가 가장 많은 변수를 찾아서 해당 결측치를 0으로 대치하고, 결측치를 제외한 평균과 0으로 대치한 후의 평균과의 차이를 구하시오.\n",
        "2. Wind 변수에 대해서 Min-Max 정규화를 수행한 후 평균값과 Z 정규화를 수행한 후 평균 값의 차이를 구하시오.\n",
        "3. 월별(5월 ~ 9월) 평균 기온을 구하시오.\n"
      ],
      "metadata": {
        "id": "K88rJufYP3ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BigData분석기사CSV파일/airquality.csv\")\n",
        "print(df.info())\n",
        "# 결측치를 제외한 평균\n",
        "# df_copy = df.dropna(axis=0) # 결측치가 있는 행 제거후\n",
        "A_mean = np.mean(df[\"Ozone\"])\n",
        "df_copy = df\n",
        "df_copy[\"Ozone\"] = df[\"Ozone\"].fillna(0)\n",
        "B_mean = np.mean(df_copy[\"Ozone\"])\n",
        "print(A_mean - B_mean)\n",
        "# 1번 문제 정답 :  answer = 10.188\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "mmScaler = MinMaxScaler()       # min-max 정규화\n",
        "stdScaler = StandardScaler()    # z 정규화\n",
        "\n",
        "df[\"mmScaler\"] = mmScaler.fit_transform(df[[\"Wind\"]])\n",
        "df[\"StandardScaler\"] = stdScaler.fit_transform(df[[\"Wind\"]])\n",
        "\n",
        "scalerMean = np.mean(df[\"mmScaler\"]) - np.mean(df[\"StandardScaler\"])\n",
        "print(scalerMean)\n",
        "\n",
        "# 2번 문제 정답 : 0.434506\n",
        "\n",
        "df.groupby(\"Month\").mean()[\"Temp\"]\n",
        "# 3번 문제 정답 : (5월 : 65.54), (6월 : 79.1), (7월 : 83.90), (8월 : 83.96), (9월 : 76.9)"
      ],
      "metadata": {
        "id": "OZH0FcjLQbA3",
        "outputId": "a59d3a0e-7125-41f5-9f54-0c21b61907cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 153 entries, 0 to 152\n",
            "Data columns (total 6 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   Ozone    116 non-null    float64\n",
            " 1   Solar.R  146 non-null    float64\n",
            " 2   Wind     153 non-null    float64\n",
            " 3   Temp     153 non-null    int64  \n",
            " 4   Month    153 non-null    int64  \n",
            " 5   Day      153 non-null    int64  \n",
            "dtypes: float64(3), int64(3)\n",
            "memory usage: 7.3 KB\n",
            "None\n",
            "10.188133874239352\n",
            "0.4346061231510147\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Month\n",
              "5    65.548387\n",
              "6    79.100000\n",
              "7    83.903226\n",
              "8    83.967742\n",
              "9    76.900000\n",
              "Name: Temp, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 제 2 유형\n",
        "데이터셋 : Bank_Personal_Loan_Modeling\n",
        "이 데이터 셋은 은행 고객 5,000명에 대한 데이터로 인구통계정보(연령, 소득 등), 고객과의 관계(담보, 증권계좌), 개인대출 등의 금융정보를 포함한다.  \n",
        "은행에서 수집한 고객 5,000명의 금융정보에 따른 대출여부가 들어있는 참조데이터를 이용허여 대출여부를 분류하는 가장 최적의 이웃의 크기값을 구하고, 이때 분류정확도를 산출하시오.  \n",
        "(단, 참조데이터는 7:3의 비율로 트레이닝 데이터와 테스트 데이터로 구분하고, 트레이닝 데이터와 테스트 데이터의 대출여부 비율도 유지한다. 또한 normalizer를 사용하여 스케일링을 진행한다)\n"
      ],
      "metadata": {
        "id": "PeMG9KcUT-2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BigData분석기사CSV파일/Bank_Personal_Loan_Modelling.csv\")\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "scaler = Normalizer()\n",
        "df.drop([\"ID\",\"ZIP Code\"], axis = 1, inplace=True)\n",
        "\n",
        "X = df.drop(\"Personal Loan\", axis = 1)\n",
        "y = df[\"Personal Loan\"]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state = 11)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "ans = []\n",
        "for i in range(1,15):\n",
        "  model = KNeighborsClassifier(n_neighbors = i)\n",
        "  model.fit(X_train,y_train)\n",
        "  pred = model.predict(X_test)\n",
        "  acc = model.score(X_test,y_test)\n",
        "  ans.append(acc)\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "id": "M3EfqgG1Uqu2",
        "outputId": "7a58a1a9-6c29-476c-b0e7-71a22234980b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3500, 11) (1500, 11) (3500,) (1500,)\n",
            "[0.9153333333333333, 0.908, 0.9126666666666666, 0.908, 0.9166666666666666, 0.9086666666666666, 0.9106666666666666, 0.9086666666666666, 0.9066666666666666, 0.91, 0.9106666666666666, 0.9086666666666666, 0.9086666666666666, 0.9093333333333333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3유형\n",
        "한 고등학교의 학생 100명의 키가 height.csv에 저장되어 있다.\n",
        "1. 데이터의 표본분산을 구하시오\n",
        "2. 학생들의 평균키가 165인지 단일표본 t검정을 실행하려 한다. 검정 통계량을 구하시오\n",
        "3. 위 통계량의 p값을 구하고 유의수준 하에 가설검정 결과를 채택 기각중 하나를 선택하시오\n",
        "\n"
      ],
      "metadata": {
        "id": "blcBFYgIaC-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BigData분석기사CSV파일/height.csv\")\n",
        "\n",
        "import numpy as np\n",
        "var = np.var(df, ddof=0) # ddof = 0이면 표본분산, ddof=1이면 불편분산\n",
        "print(var)\n",
        "\n",
        "from scipy.stats import ttest_1samp\n",
        "# print(help(ttest_1samp))\n",
        "print(ttest_1samp(df,165))\n",
        "# t검정 통계량 구하는 공식 = (np.mean(df) - len(df)) / (np.std(df, ddof=1) / np.sqrt(n))"
      ],
      "metadata": {
        "id": "SO4uH_zOaCNQ",
        "outputId": "49337b9a-e182-46e4-f56d-dc8e9db1e2c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "height    67.273379\n",
            "dtype: float64\n",
            "TtestResult(statistic=array([1.83299146]), pvalue=array([0.06980908]), df=array([99]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2회차\n",
        "## 1유형\n",
        "데이터셋 : HR-Employee-Attrition  \n",
        "주어지는 데이터는 IBM의 근무자에 대한 직무정보와 퇴사여부를 정리한 것이다.  \n",
        "- 1. 데이터에서 'Attrition'은 퇴사여부에 대한 종속변수에 해당한다. 종속변수의 값을 다음과 같이 수치로 변환해 새 칼럼으로 추가하고 각 범주별 레코드 수를 계산하시오.\n",
        "- 2. 데이터셋의 데이터타입별 칼럼 개수를 계산하고, 범주형 변수 중 유일한 값을 1개만 가지고 있는 칼럼을 찾아내어 그 변수를 데이터에서 제거하시오.\n",
        "- 3. 원래 데이터에서 숫자형인 칼럼만 추출하여 새로운 데이터프레임을 생성하고, 각 변수간의 상관계수를 구하고, 상관계수가 0.9 이상인 두 개의 칼럼을 찾아내어 그 변수 중 하나를 제거하시오."
      ],
      "metadata": {
        "id": "LAK5QIBdqolL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BigData분석기사CSV파일/HR-Employee-Attrition.csv\")\n",
        "\n",
        "# print(df[\"Attrition\"]) # Yes => 1, No => 0\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "df[\"Attrition\"] = encoder.fit_transform(df[\"Attrition\"])\n",
        "print(len(df[df[\"Attrition\"]==0]))\n",
        "print(len(df[df[\"Attrition\"]==1]))\n",
        "\n",
        "# 1번문제 답 : No(0) -> 1233, Yes(1) -> 237\n",
        "# print(df.nunique().sort_values) # 1인 값은 over18뿐\n",
        "# 2번문제 답 : df.drop(\"Over18\", axis=1, inplace=True)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# print(df.columns)\n",
        "intList = []\n",
        "for i in df.columns:\n",
        "  if type(df[i][0]) == np.int64:\n",
        "    intList.append(i)\n",
        "df_copy = df[intList]\n",
        "# print(df_copy.info())\n",
        "corr = df_copy.corr(method='pearson')\n",
        "for i in intList:\n",
        "  for j in intList:\n",
        "    if corr.loc[i][j] > 0.9 and i != j:\n",
        "      print(i,j)\n",
        "# 3번문제 답 : JobLevel, MonthlyIncome 의 상관관계가 0.9가 넘으므로 둘중 하나는 제거해준다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE5sWS0QrgYR",
        "outputId": "210d94b4-bbe5-407d-e2d5-4a623ee636e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1233\n",
            "237\n",
            "JobLevel MonthlyIncome\n",
            "MonthlyIncome JobLevel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2유형\n",
        "데이터셋 : Parkinsons.csv\n",
        "환자들의 뇌를 촬영한 사진의 상태를 기록한 자료에 각 환자의 상태를 status로 추가한 테이블이다.  \n",
        " - 데이터셋을 이용하여 파킨슨병을 예측하는 모델을 로지스틱 회귀모형을 적용하여 생성하고, 이때 파킨슨병을 예측하는데 영향을 미치는 변수를 중요한 순서대로 3개 선정하시오.  \n",
        " 이 모델에서 파킨슨병으로 진단하는 기준(threshold, cutoff)을 0.5로 했을때와 0.8로 했을대 F1-스코어를 비교하고 해석하시오.  \n",
        "\n",
        "분석조건  \n",
        "1. 필요없는 칼럼인 'name' 제거 O\n",
        "2. 데이터 정규화는 min-max스케일러 사용 O\n",
        "3. status는 카테고리 타입으로 변환\n",
        "4. 트레이닝 셋과 테스트셋의 비율은 9:1\n",
        "5. 모델의 최적화 방법론으로 \"bfgs\" 사용"
      ],
      "metadata": {
        "id": "jNAQFHZlrgo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BigData분석기사CSV파일/Parkinsons.csv\")\n",
        "\n",
        "# print(df.head())\n",
        "\n",
        "df.drop(\"name\",axis=1,inplace=True)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X = df.drop(\"status\", axis = 1)\n",
        "y = df[\"status\"]\n",
        "df_columns = X.columns\n",
        "df = scaler.fit_transform(X)\n",
        "df = pd.DataFrame(df, columns = df_columns)\n",
        "\n",
        "y = y.astype('category')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.1, random_state=11)\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "model = sm.Logit(y_train, X_train)\n",
        "results = model.fit(method='bfgs', maxiter=1000)\n",
        "results.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "jcaYWNlxsqu3",
        "outputId": "3c8fd65e-937c-428e-eb12-1d7ab26788db"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.220729\n",
            "         Iterations: 288\n",
            "         Function evaluations: 294\n",
            "         Gradient evaluations: 294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:                 status   No. Observations:                  175\n",
              "Model:                          Logit   Df Residuals:                      153\n",
              "Method:                           MLE   Df Model:                           21\n",
              "Date:                Thu, 30 Nov 2023   Pseudo R-squ.:                  0.5995\n",
              "Time:                        06:52:25   Log-Likelihood:                -38.628\n",
              "converged:                       True   LL-Null:                       -96.439\n",
              "Covariance Type:            nonrobust   LLR p-value:                 4.507e-15\n",
              "====================================================================================\n",
              "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------------\n",
              "MDVP:Fo(Hz)          0.0047      0.021      0.223      0.824      -0.037       0.046\n",
              "MDVP:Fhi(Hz)        -0.0027      0.006     -0.485      0.627      -0.014       0.008\n",
              "MDVP:Flo(Hz)        -0.0067      0.011     -0.589      0.556      -0.029       0.016\n",
              "MDVP:Jitter(%)   -2252.0277   1367.884     -1.646      0.100   -4933.030     428.975\n",
              "MDVP:Jitter(Abs)   -23.2665    9.5e+04     -0.000      1.000   -1.86e+05    1.86e+05\n",
              "MDVP:RAP           387.8800   1.49e+05      0.003      0.998   -2.91e+05    2.92e+05\n",
              "MDVP:PPQ         -1390.3931   1996.542     -0.696      0.486   -5303.543    2522.757\n",
              "Jitter:DDP        1170.0066   4.97e+04      0.024      0.981   -9.62e+04    9.86e+04\n",
              "MDVP:Shimmer       805.7570   1162.112      0.693      0.488   -1471.940    3083.454\n",
              "MDVP:Shimmer(dB)    26.7167     34.235      0.780      0.435     -40.383      93.816\n",
              "Shimmer:APQ3      -119.9525   1.22e+05     -0.001      0.999   -2.39e+05    2.39e+05\n",
              "Shimmer:APQ5      -531.0545    501.518     -1.059      0.290   -1514.012     451.904\n",
              "MDVP:APQ           109.3672    457.855      0.239      0.811    -788.012    1006.747\n",
              "Shimmer:DDA       -361.3690   4.07e+04     -0.009      0.993   -8.02e+04    7.94e+04\n",
              "NHR                 -8.6706     43.194     -0.201      0.841     -93.329      75.988\n",
              "HNR                 -0.0731      0.203     -0.359      0.719      -0.472       0.326\n",
              "RPDE                -6.5908      4.598     -1.433      0.152     -15.603       2.422\n",
              "DFA                 11.4958      8.580      1.340      0.180      -5.320      28.311\n",
              "spread1              1.0912      1.188      0.919      0.358      -1.236       3.419\n",
              "spread2             12.9357      7.163      1.806      0.071      -1.104      26.975\n",
              "D2                  -0.2367      1.386     -0.171      0.864      -2.954       2.481\n",
              "PPE                 23.6605     18.184      1.301      0.193     -11.980      59.301\n",
              "====================================================================================\n",
              "\n",
              "Possibly complete quasi-separation: A fraction 0.11 of observations can be\n",
              "perfectly predicted. This might indicate that there is complete\n",
              "quasi-separation. In this case some parameters will not be identified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>status</td>      <th>  No. Observations:  </th>  <td>   175</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   153</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    21</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Thu, 30 Nov 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.5995</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>06:52:25</td>     <th>  Log-Likelihood:    </th> <td> -38.628</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -96.439</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.507e-15</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:Fo(Hz)</th>      <td>    0.0047</td> <td>    0.021</td> <td>    0.223</td> <td> 0.824</td> <td>   -0.037</td> <td>    0.046</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:Fhi(Hz)</th>     <td>   -0.0027</td> <td>    0.006</td> <td>   -0.485</td> <td> 0.627</td> <td>   -0.014</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:Flo(Hz)</th>     <td>   -0.0067</td> <td>    0.011</td> <td>   -0.589</td> <td> 0.556</td> <td>   -0.029</td> <td>    0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:Jitter(%)</th>   <td>-2252.0277</td> <td> 1367.884</td> <td>   -1.646</td> <td> 0.100</td> <td>-4933.030</td> <td>  428.975</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:Jitter(Abs)</th> <td>  -23.2665</td> <td>  9.5e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-1.86e+05</td> <td> 1.86e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:RAP</th>         <td>  387.8800</td> <td> 1.49e+05</td> <td>    0.003</td> <td> 0.998</td> <td>-2.91e+05</td> <td> 2.92e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:PPQ</th>         <td>-1390.3931</td> <td> 1996.542</td> <td>   -0.696</td> <td> 0.486</td> <td>-5303.543</td> <td> 2522.757</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Jitter:DDP</th>       <td> 1170.0066</td> <td> 4.97e+04</td> <td>    0.024</td> <td> 0.981</td> <td>-9.62e+04</td> <td> 9.86e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:Shimmer</th>     <td>  805.7570</td> <td> 1162.112</td> <td>    0.693</td> <td> 0.488</td> <td>-1471.940</td> <td> 3083.454</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:Shimmer(dB)</th> <td>   26.7167</td> <td>   34.235</td> <td>    0.780</td> <td> 0.435</td> <td>  -40.383</td> <td>   93.816</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Shimmer:APQ3</th>     <td> -119.9525</td> <td> 1.22e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-2.39e+05</td> <td> 2.39e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Shimmer:APQ5</th>     <td> -531.0545</td> <td>  501.518</td> <td>   -1.059</td> <td> 0.290</td> <td>-1514.012</td> <td>  451.904</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MDVP:APQ</th>         <td>  109.3672</td> <td>  457.855</td> <td>    0.239</td> <td> 0.811</td> <td> -788.012</td> <td> 1006.747</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Shimmer:DDA</th>      <td> -361.3690</td> <td> 4.07e+04</td> <td>   -0.009</td> <td> 0.993</td> <td>-8.02e+04</td> <td> 7.94e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>NHR</th>              <td>   -8.6706</td> <td>   43.194</td> <td>   -0.201</td> <td> 0.841</td> <td>  -93.329</td> <td>   75.988</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>HNR</th>              <td>   -0.0731</td> <td>    0.203</td> <td>   -0.359</td> <td> 0.719</td> <td>   -0.472</td> <td>    0.326</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>RPDE</th>             <td>   -6.5908</td> <td>    4.598</td> <td>   -1.433</td> <td> 0.152</td> <td>  -15.603</td> <td>    2.422</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>DFA</th>              <td>   11.4958</td> <td>    8.580</td> <td>    1.340</td> <td> 0.180</td> <td>   -5.320</td> <td>   28.311</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>spread1</th>          <td>    1.0912</td> <td>    1.188</td> <td>    0.919</td> <td> 0.358</td> <td>   -1.236</td> <td>    3.419</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>spread2</th>          <td>   12.9357</td> <td>    7.163</td> <td>    1.806</td> <td> 0.071</td> <td>   -1.104</td> <td>   26.975</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>D2</th>               <td>   -0.2367</td> <td>    1.386</td> <td>   -0.171</td> <td> 0.864</td> <td>   -2.954</td> <td>    2.481</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>PPE</th>              <td>   23.6605</td> <td>   18.184</td> <td>    1.301</td> <td> 0.193</td> <td>  -11.980</td> <td>   59.301</td>\n",
              "</tr>\n",
              "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.11 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}   &      status      & \\textbf{  No. Observations:  } &      175    \\\\\n\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &      153    \\\\\n\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &       21    \\\\\n\\textbf{Date:}            & Thu, 30 Nov 2023 & \\textbf{  Pseudo R-squ.:     } &   0.5995    \\\\\n\\textbf{Time:}            &     06:52:25     & \\textbf{  Log-Likelihood:    } &   -38.628   \\\\\n\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -96.439   \\\\\n\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 4.507e-15   \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                          & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{MDVP:Fo(Hz)}      &       0.0047  &        0.021     &     0.223  &         0.824        &       -0.037    &        0.046     \\\\\n\\textbf{MDVP:Fhi(Hz)}     &      -0.0027  &        0.006     &    -0.485  &         0.627        &       -0.014    &        0.008     \\\\\n\\textbf{MDVP:Flo(Hz)}     &      -0.0067  &        0.011     &    -0.589  &         0.556        &       -0.029    &        0.016     \\\\\n\\textbf{MDVP:Jitter(\\%)}  &   -2252.0277  &     1367.884     &    -1.646  &         0.100        &    -4933.030    &      428.975     \\\\\n\\textbf{MDVP:Jitter(Abs)} &     -23.2665  &      9.5e+04     &    -0.000  &         1.000        &    -1.86e+05    &     1.86e+05     \\\\\n\\textbf{MDVP:RAP}         &     387.8800  &     1.49e+05     &     0.003  &         0.998        &    -2.91e+05    &     2.92e+05     \\\\\n\\textbf{MDVP:PPQ}         &   -1390.3931  &     1996.542     &    -0.696  &         0.486        &    -5303.543    &     2522.757     \\\\\n\\textbf{Jitter:DDP}       &    1170.0066  &     4.97e+04     &     0.024  &         0.981        &    -9.62e+04    &     9.86e+04     \\\\\n\\textbf{MDVP:Shimmer}     &     805.7570  &     1162.112     &     0.693  &         0.488        &    -1471.940    &     3083.454     \\\\\n\\textbf{MDVP:Shimmer(dB)} &      26.7167  &       34.235     &     0.780  &         0.435        &      -40.383    &       93.816     \\\\\n\\textbf{Shimmer:APQ3}     &    -119.9525  &     1.22e+05     &    -0.001  &         0.999        &    -2.39e+05    &     2.39e+05     \\\\\n\\textbf{Shimmer:APQ5}     &    -531.0545  &      501.518     &    -1.059  &         0.290        &    -1514.012    &      451.904     \\\\\n\\textbf{MDVP:APQ}         &     109.3672  &      457.855     &     0.239  &         0.811        &     -788.012    &     1006.747     \\\\\n\\textbf{Shimmer:DDA}      &    -361.3690  &     4.07e+04     &    -0.009  &         0.993        &    -8.02e+04    &     7.94e+04     \\\\\n\\textbf{NHR}              &      -8.6706  &       43.194     &    -0.201  &         0.841        &      -93.329    &       75.988     \\\\\n\\textbf{HNR}              &      -0.0731  &        0.203     &    -0.359  &         0.719        &       -0.472    &        0.326     \\\\\n\\textbf{RPDE}             &      -6.5908  &        4.598     &    -1.433  &         0.152        &      -15.603    &        2.422     \\\\\n\\textbf{DFA}              &      11.4958  &        8.580     &     1.340  &         0.180        &       -5.320    &       28.311     \\\\\n\\textbf{spread1}          &       1.0912  &        1.188     &     0.919  &         0.358        &       -1.236    &        3.419     \\\\\n\\textbf{spread2}          &      12.9357  &        7.163     &     1.806  &         0.071        &       -1.104    &       26.975     \\\\\n\\textbf{D2}               &      -0.2367  &        1.386     &    -0.171  &         0.864        &       -2.954    &        2.481     \\\\\n\\textbf{PPE}              &      23.6605  &       18.184     &     1.301  &         0.193        &      -11.980    &       59.301     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Logit Regression Results}\n\\end{center}\n\nPossibly complete quasi-separation: A fraction 0.11 of observations can be \\newline\n perfectly predicted. This might indicate that there is complete \\newline\n quasi-separation. In this case some parameters will not be identified."
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3유형\n",
        "(data/Titanic.csv)는 타이타닉호의 침몰 사건에서 생존한 승객 및 사망한 승객의 정보를 포함한  자료이다. 아래 데이터를 이용하여 생존 여부(Survived)를 예측하고자 한다.  \n",
        "\n",
        "- ①. Gender와 Survived 변수 간의 독립성 검정을 실시하였을 때, 카이제곱 통계량은?  \n",
        "- ②. Gender, SibSp, Parch, Fare를 독립변수로 사용하여 로지스틱 회귀모형을 실시하였을 때, Parch 변수의 계수값은?   \n",
        "- ③. 위 ②번 문제에서 추정된 로지스틱 회귀모형에서 SibSp 변수가 한 단위 증가할 때 생존할 오즈비(Odds ratio) 값은?"
      ],
      "metadata": {
        "id": "iHgH3wAesurf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BigData분석기사CSV파일/titanic.csv\")\n",
        "# df.head()\n",
        "crossTable = pd.crosstab(df[\"Sex\"], df[\"Survived\"])\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "stats = chi2_contingency(crossTable)[0]\n",
        "print(stats)\n",
        "# 1번 문제 정답 : 206.71\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df[\"Sex\"] = encoder.fit_transform(df[[\"Sex\"]])\n",
        "\n",
        "X = df[[\"Sex\",\"SibSp\", \"Parch\", \"Fare\"]]\n",
        "y = df[\"Survived\"]\n",
        "model = sm.Logit(y,X)\n",
        "results = model.fit()\n",
        "results.summary()\n",
        "# 2번 문제 정답 : -0.0313\n"
      ],
      "metadata": {
        "id": "Ua5IXshptkqa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "6f1d9e89-21f9-4019-c829-c2b549f5693b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260.71702016732104\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.501060\n",
            "         Iterations 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:               Survived   No. Observations:                  891\n",
              "Model:                          Logit   Df Residuals:                      887\n",
              "Method:                           MLE   Df Model:                            3\n",
              "Date:                Thu, 30 Nov 2023   Pseudo R-squ.:                  0.2476\n",
              "Time:                        07:17:39   Log-Likelihood:                -446.44\n",
              "converged:                       True   LL-Null:                       -593.33\n",
              "Covariance Type:            nonrobust   LLR p-value:                 2.223e-63\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Sex           -1.9111      0.129    -14.799      0.000      -2.164      -1.658\n",
              "SibSp         -0.2425      0.086     -2.819      0.005      -0.411      -0.074\n",
              "Parch         -0.0313      0.104     -0.303      0.762      -0.234       0.172\n",
              "Fare           0.0201      0.003      7.437      0.000       0.015       0.025\n",
              "==============================================================================\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>       <td>Survived</td>     <th>  No. Observations:  </th>  <td>   891</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   887</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Thu, 30 Nov 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.2476</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>07:17:39</td>     <th>  Log-Likelihood:    </th> <td> -446.44</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -593.33</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.223e-63</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Sex</th>   <td>   -1.9111</td> <td>    0.129</td> <td>  -14.799</td> <td> 0.000</td> <td>   -2.164</td> <td>   -1.658</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>SibSp</th> <td>   -0.2425</td> <td>    0.086</td> <td>   -2.819</td> <td> 0.005</td> <td>   -0.411</td> <td>   -0.074</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Parch</th> <td>   -0.0313</td> <td>    0.104</td> <td>   -0.303</td> <td> 0.762</td> <td>   -0.234</td> <td>    0.172</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fare</th>  <td>    0.0201</td> <td>    0.003</td> <td>    7.437</td> <td> 0.000</td> <td>    0.015</td> <td>    0.025</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}   &     Survived     & \\textbf{  No. Observations:  } &      891    \\\\\n\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &      887    \\\\\n\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        3    \\\\\n\\textbf{Date:}            & Thu, 30 Nov 2023 & \\textbf{  Pseudo R-squ.:     } &   0.2476    \\\\\n\\textbf{Time:}            &     07:17:39     & \\textbf{  Log-Likelihood:    } &   -446.44   \\\\\n\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -593.33   \\\\\n\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 2.223e-63   \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{Sex}   &      -1.9111  &        0.129     &   -14.799  &         0.000        &       -2.164    &       -1.658     \\\\\n\\textbf{SibSp} &      -0.2425  &        0.086     &    -2.819  &         0.005        &       -0.411    &       -0.074     \\\\\n\\textbf{Parch} &      -0.0313  &        0.104     &    -0.303  &         0.762        &       -0.234    &        0.172     \\\\\n\\textbf{Fare}  &       0.0201  &        0.003     &     7.437  &         0.000        &        0.015    &        0.025     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Logit Regression Results}\n\\end{center}"
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}